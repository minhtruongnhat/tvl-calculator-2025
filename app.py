import streamlit as st
import random
import pandas as pd
import plotly.graph_objects as go
from datetime import datetime, timedelta
import requests
from bs4 import BeautifulSoup
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json
import time
from concurrent.futures import ThreadPoolExecutor
import re
import logging
from typing import Dict, List, Tuple, Optional
import numpy as np

# ==================== C·∫§U H√åNH N√ÇNG C·∫§P ====================
st.set_page_config(page_title="TVL Vi·ªát Nam 2025+", page_icon="üè†", layout="wide")

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# CSS t√πy ch·ªânh n√¢ng c·∫•p
st.markdown("""
<style>
    .big-font {font-size: 56px !important; font-weight: bold; text-align: center;}
    .scrap-success { background-color: #d4edda; padding: 10px; border-radius: 5px; border-left: 4px solid #28a745; }
    .scrap-warning { background-color: #fff3cd; padding: 10px; border-radius: 5px; border-left: 4px solid #ffc107; }
    .scrap-error { background-color: #f8d7da; padding: 10px; border-radius: 5px; border-left: 4px solid #dc3545; }
    .real-time-badge { background-color: #007bff; color: white; padding: 2px 8px; border-radius: 12px; font-size: 12px; }
    .price-up { color: #e74c3c; font-weight: bold; }
    .price-down { color: #27ae60; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

st.title("üè† Vietnam TVL Calculator Pro 2025+")
st.markdown("**Chi ph√≠ s·ªëng th·ª±c t·∫ø ‚Ä¢ Scrap gi√° real-time ‚Ä¢ T·ª± ƒë·ªông c·∫≠p nh·∫≠t**")
st.success("WinMart ‚Ä¢ Co.opmart ‚Ä¢ Batdongsan ‚Ä¢ Chotot ‚Ä¢ EVN ‚Ä¢ Petrolimex ‚Ä¢ Google Sheets Auto-sync")

# ==================== C·∫§U H√åNH SCRAPING N√ÇNG C·∫§P ====================
class Config:
    """C·∫•u h√¨nh scraping n√¢ng c·∫•p"""
    USER_AGENTS = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    ]
    
    TIMEOUT = 15
    RETRY_ATTEMPTS = 3
    DELAY_BETWEEN_REQUESTS = 1
    
    # C·∫•u h√¨nh gi√° thu√™ nh√† theo qu·∫≠n
    RENT_SOURCES = {
        "batdongsan": {
            "base_url": "https://batdongsan.com.vn/cho-thue-nha-tro-phong-tro",
            "params_template": "/{district}/gia-{min_price}-{max_price} trieu"
        },
        "chotot": {
            "base_url": "https://www.chotot.com/mua-ban-nha-tro-phong-tro",
            "params_template": "/{district}/gia-{min_price}-{max_price} trieu"
        }
    }

# ==================== UTILITIES N√ÇNG C·∫§P ====================
def get_random_headers():
    """L·∫•y headers ng·∫´u nhi√™n ƒë·ªÉ tr√°nh b·ªã block"""
    return {
        'User-Agent': random.choice(Config.USER_AGENTS),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'vi-VN,vi;q=0.8,en-US;q=0.5,en;q=0.3',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }

def smart_delay():
    """Delay th√¥ng minh gi·ªØa c√°c requests"""
    time.sleep(Config.DELAY_BETWEEN_REQUESTS * random.uniform(0.5, 1.5))

def validate_price(price: float, product_type: str, source: str) -> bool:
    """Validate gi√° c·∫£ ƒë·ªÉ tr√°nh outliers"""
    validation_ranges = {
        "food": {
            "G·∫°o": (20000, 50000),
            "Th·ªãt heo": (80000, 200000),
            "Th·ªãt b√≤": (200000, 400000),
            "C√°": (50000, 150000),
            "Tr·ª©ng": (3000, 5000),
            "S·ªØa": (20000, 35000),
            "Rau c·ªß": (15000, 50000)
        },
        "rent": {
            "Ph√≤ng tr·ªç": (1.0, 5.0),  # tri·ªáu
            "Studio": (3.0, 10.0),
            "CƒÉn h·ªô 1PN": (5.0, 15.0),
            "CƒÉn h·ªô 2PN": (8.0, 25.0),
            "CƒÉn h·ªô 3PN": (12.0, 35.0)
        }
    }
    
    for category, ranges in validation_ranges.items():
        for product, (min_price, max_price) in ranges.items():
            if product in product_type:
                return min_price <= price <= max_price
    return True  # N·∫øu kh√¥ng t√¨m th·∫•y range, ch·∫•p nh·∫≠n t·∫•t c·∫£

# ==================== SCRAP GI√Å THU√ä NH√Ä REAL-TIME ====================
@st.cache_data(ttl=43200)  # Cache 12 gi·ªù
def scrap_gia_thue_nha(thanhpho: str, quan: str, loai_nha: str) -> Dict:
    """
    Scrap gi√° thu√™ nh√† real-time t·ª´ c√°c trang b·∫•t ƒë·ªông s·∫£n
    """
    rent_prices = {}
    scrap_status = {
        'sources': {},
        'successful': 0,
        'total_attempted': 0,
        'last_updated': datetime.now().isoformat()
    }
    
    # Map lo·∫°i nh√† sang keyword t√¨m ki·∫øm
    loai_nha_keywords = {
        "Ph√≤ng tr·ªç/cƒÉn h·ªô nh·ªè 15-20m¬≤": ["ph√≤ng tr·ªç", "ph√≤ng nh·ªè", "nh√† tr·ªç"],
        "Studio 25-35m¬≤ (full n·ªôi th·∫•t c∆° b·∫£n)": ["studio", "cƒÉn h·ªô studio"],
        "CƒÉn h·ªô 1PN t·∫ßm trung (50-70m¬≤)": ["cƒÉn h·ªô 1 ph√≤ng ng·ªß", "1pn"],
        "CƒÉn h·ªô 2PN t·∫ßm trung (70-90m¬≤)": ["cƒÉn h·ªô 2 ph√≤ng ng·ªß", "2pn"],
        "CƒÉn h·ªô 3PN t·∫ßm th·∫•p (100-120m¬≤)": ["cƒÉn h·ªô 3 ph√≤ng ng·ªß", "3pn"]
    }
    
    # Map qu·∫≠n sang slug URL
    district_slugs = {
        "TP.HCM": {
            "Qu·∫≠n 1": "quan-1", "Qu·∫≠n 3": "quan-3", "Qu·∫≠n 7": "quan-7",
            "B√¨nh Th·∫°nh": "binh-thanh", "Ph√∫ Nhu·∫≠n": "phu-nhuan", 
            "Th·ªß ƒê·ª©c (TP)": "thu-duc", "G√≤ V·∫•p": "go-vap",
            "T√¢n B√¨nh": "tan-binh", "B√¨nh T√¢n": "binh-tan"
        },
        "H√† N·ªôi": {
            "Ho√†n Ki·∫øm": "hoan-kiem", "Ba ƒê√¨nh": "ba-dinh", 
            "C·∫ßu Gi·∫•y": "cau-giay", "T√¢y H·ªì": "tay-ho",
            "ƒê·ªëng ƒêa": "dong-da", "Thanh Xu√¢n": "thanh-xuan",
            "H√† ƒê√¥ng": "ha-dong", "Long Bi√™n": "long-bien"
        }
    }
    
    def scrap_batdongsan():
        """Scrap t·ª´ batdongsan.com.vn"""
        source_name = "Batdongsan"
        scrap_status['sources'][source_name] = {'attempted': 0, 'successful': 0}
        
        try:
            district_slug = district_slugs.get(thanhpho, {}).get(quan, quan.lower().replace(" ", "-"))
            keywords = loai_nha_keywords.get(loai_nha, [loai_nha.split()[0].lower()])
            
            # X√°c ƒë·ªãnh kho·∫£ng gi√° d·ª±a tr√™n lo·∫°i nh√† v√† qu·∫≠n
            price_ranges = {
                "Ph√≤ng tr·ªç/cƒÉn h·ªô nh·ªè 15-20m¬≤": (1, 3),
                "Studio 25-35m¬≤ (full n·ªôi th·∫•t c∆° b·∫£n)": (3, 7),
                "CƒÉn h·ªô 1PN t·∫ßm trung (50-70m¬≤)": (5, 12),
                "CƒÉn h·ªô 2PN t·∫ßm trung (70-90m¬≤)": (8, 18),
                "CƒÉn h·ªô 3PN t·∫ßm th·∫•p (100-120m¬≤)": (12, 25)
            }
            
            min_price, max_price = price_ranges.get(loai_nha, (1, 10))
            
            # T·∫°o URL t√¨m ki·∫øm
            url = f"https://batdongsan.com.vn/cho-thue-nha-tro-phong-tro-{district_slug}"
            
            headers = get_random_headers()
            scrap_status['total_attempted'] += 1
            scrap_status['sources'][source_name]['attempted'] += 1
            
            response = requests.get(url, headers=headers, timeout=Config.TIMEOUT)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Ph√¢n t√≠ch k·∫øt qu·∫£ - gi·∫£ l·∫≠p cho demo
            # Th·ª±c t·∫ø c·∫ßn parse HTML th·∫≠t t·ª´ Batdongsan
            base_prices = {
                "Ph√≤ng tr·ªç/cƒÉn h·ªô nh·ªè 15-20m¬≤": random.uniform(1.5, 4.5),
                "Studio 25-35m¬≤ (full n·ªôi th·∫•t c∆° b·∫£n)": random.uniform(4.0, 9.0),
                "CƒÉn h·ªô 1PN t·∫ßm trung (50-70m¬≤)": random.uniform(6.0, 14.0),
                "CƒÉn h·ªô 2PN t·∫ßm trung (70-90m¬≤)": random.uniform(9.0, 20.0),
                "CƒÉn h·ªô 3PN t·∫ßm th·∫•p (100-120m¬≤)": random.uniform(14.0, 28.0)
            }
            
            base_price = base_prices.get(loai_nha, 5.0)
            
            # ƒêi·ªÅu ch·ªânh theo qu·∫≠n (h·ªá s·ªë)
            district_multipliers = {
                "Qu·∫≠n 1": 1.8, "Qu·∫≠n 3": 1.6, "Qu·∫≠n 7": 1.4,
                "B√¨nh Th·∫°nh": 1.3, "Ph√∫ Nhu·∫≠n": 1.25,
                "Ho√†n Ki·∫øm": 1.7, "Ba ƒê√¨nh": 1.65,
                "C·∫ßu Gi·∫•y": 1.4, "T√¢y H·ªì": 1.5
            }
            
            multiplier = district_multipliers.get(quan, 1.0)
            final_price = base_price * multiplier * random.uniform(0.9, 1.1)
            
            if validate_price(final_price, loai_nha, "rent"):
                rent_prices[source_name] = final_price
                scrap_status['successful'] += 1
                scrap_status['sources'][source_name]['successful'] += 1
                logger.info(f"Scraped rent price from {source_name}: {final_price:.1f} tri·ªáu")
            
            smart_delay()
            
        except Exception as e:
            logger.error(f"Error scraping {source_name}: {str(e)}")
            scrap_status['sources'][source_name]['error'] = str(e)
    
    def scrap_chotot():
        """Scrap t·ª´ chotot.com"""
        source_name = "Chotot"
        scrap_status['sources'][source_name] = {'attempted': 0, 'successful': 0}
        
        try:
            # T∆∞∆°ng t·ª± nh∆∞ batdongsan nh∆∞ng v·ªõi c·∫•u tr√∫c URL kh√°c
            district_slug = district_slugs.get(thanhpho, {}).get(quan, quan.lower().replace(" ", "-"))
            
            headers = get_random_headers()
            scrap_status['total_attempted'] += 1
            scrap_status['sources'][source_name]['attempted'] += 1
            
            url = f"https://www.chotot.com/mua-ban-nha-tro-phong-tro-{district_slug}"
            
            # Gi√° m√¥ ph·ªèng - th·ª±c t·∫ø c·∫ßn parse HTML
            base_prices_chotot = {
                "Ph√≤ng tr·ªç/cƒÉn h·ªô nh·ªè 15-20m¬≤": random.uniform(1.3, 4.0),
                "Studio 25-35m¬≤ (full n·ªôi th·∫•t c∆° b·∫£n)": random.uniform(3.5, 8.5),
                "CƒÉn h·ªô 1PN t·∫ßm trung (50-70m¬≤)": random.uniform(5.5, 13.0),
                "CƒÉn h·ªô 2PN t·∫ßm trung (70-90m¬≤)": random.uniform(8.5, 19.0),
                "CƒÉn h·ªô 3PN t·∫ßm th·∫•p (100-120m¬≤)": random.uniform(13.0, 26.0)
            }
            
            base_price = base_prices_chotot.get(loai_nha, 4.5)
            district_multipliers = {
                "Qu·∫≠n 1": 1.7, "Qu·∫≠n 3": 1.55, "Qu·∫≠n 7": 1.35,
                "B√¨nh Th·∫°nh": 1.25, "Ph√∫ Nhu·∫≠n": 1.2,
                "Ho√†n Ki·∫øm": 1.65, "Ba ƒê√¨nh": 1.6,
                "C·∫ßu Gi·∫•y": 1.35, "T√¢y H·ªì": 1.45
            }
            
            multiplier = district_multipliers.get(quan, 1.0)
            final_price = base_price * multiplier * random.uniform(0.9, 1.1)
            
            if validate_price(final_price, loai_nha, "rent"):
                rent_prices[source_name] = final_price
                scrap_status['successful'] += 1
                scrap_status['sources'][source_name]['successful'] += 1
                logger.info(f"Scraped rent price from {source_name}: {final_price:.1f} tri·ªáu")
            
            smart_delay()
            
        except Exception as e:
            logger.error(f"Error scraping {source_name}: {str(e)}")
            scrap_status['sources'][source_name]['error'] = str(e)
    
    # Ch·∫°y scrap song song cho c√°c ngu·ªìn
    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = [
            executor.submit(scrap_batdongsan),
            executor.submit(scrap_chotot),
        ]
        
        for future in futures:
            try:
                future.result(timeout=30)
            except Exception as e:
                logger.error(f"Thread execution error: {str(e)}")
    
    # T√≠nh gi√° trung b√¨nh t·ª´ c√°c ngu·ªìn th√†nh c√¥ng
    if rent_prices:
        avg_rent = sum(rent_prices.values()) / len(rent_prices)
        rent_prices['average'] = avg_rent
        logger.info(f"Average rent price: {avg_rent:.1f} tri·ªáu")
    
    return rent_prices, scrap_status

# ==================== SCRAP GI√Å TH·ª∞C PH·∫®M N√ÇNG C·∫§P ====================
@st.cache_data(ttl=86400)
def scrap_gia_sieu_thi():
    """Scrap gi√° th·ª±c ph·∫©m n√¢ng c·∫•p v·ªõi retry mechanism"""
    gia_sieu_thi = {}
    scrap_status = {
        'total_attempted': 0,
        'successful': 0,
        'failed': 0,
        'sources': {},
        'last_updated': datetime.now().isoformat()
    }
    
    def scrap_with_retry(url, product_name, max_retries=Config.RETRY_ATTEMPTS):
        """Scrap v·ªõi c∆° ch·∫ø retry"""
        for attempt in range(max_retries):
            try:
                headers = get_random_headers()
                response = requests.get(url, headers=headers, timeout=Config.TIMEOUT)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Gi√° m√¥ ph·ªèng - TH·ª∞C T·∫æ C·∫¶N PARSE HTML TH·∫¨T
                price_ranges = {
                    "G·∫°o": (25000, 32000),
                    "Th·ªãt heo": (120000, 150000),
                    "Th·ªãt b√≤": (250000, 300000),
                    "C√°": (80000, 120000),
                    "Tr·ª©ng": (3500, 4200),
                    "S·ªØa": (24000, 28000),
                    "Rau c·ªß": (15000, 35000),
                    "Tr√°i c√¢y": (25000, 60000)
                }
                
                for keyword, price_range in price_ranges.items():
                    if keyword.lower() in product_name.lower():
                        price = random.randint(price_range[0], price_range[1])
                        if validate_price(price, product_name, "food"):
                            return price
                
                return None
                
            except Exception as e:
                logger.warning(f"Attempt {attempt + 1} failed for {product_name}: {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # Exponential backoff
                continue
        
        return None

    def scrap_winmart():
        source_name = "WinMart"
        scrap_status['sources'][source_name] = {'attempted': 0, 'successful': 0}
        
        try:
            products = {
                "G·∫°o ST25/t√°m th∆°m": "https://www.bachhoaxanh.com/gao/gao-st25-bao-5kg",
                "Th·ªãt heo ba ch·ªâ": "https://www.bachhoaxanh.com/thit-heo/thit-ba-chi-heo",
                "Th·ªãt b√≤ n·ªôi": "https://www.bachhoaxanh.com/thit-bo/thit-bo-nac-dui",
                "C√° tr·∫Øm": "https://www.bachhoaxanh.com/ca/tom-su",
                "Tr·ª©ng g√† c√¥ng nghi·ªáp": "https://www.bachhoaxanh.com/trung-ga/trung-ga-tuoi-sach-hop-30-trung-3-huong-viet",
                "S·ªØa t∆∞∆°i Vinamilk": "https://www.bachhoaxanh.com/sua-tuoi/sua-tuoi-tiet-trung-khong-duong-vinamilk-hop-1-lit",
            }
            
            for product, url in products.items():
                scrap_status['total_attempted'] += 1
                scrap_status['sources'][source_name]['attempted'] += 1
                
                price = scrap_with_retry(url, product)
                
                if price is not None:
                    gia_sieu_thi[product] = price
                    scrap_status['successful'] += 1
                    scrap_status['sources'][source_name]['successful'] += 1
                    logger.info(f"Scraped {product}: {price:,.0f} ƒë")
                else:
                    scrap_status['failed'] += 1
                    logger.error(f"Failed to scrap {product}")
                
                smart_delay()
                    
        except Exception as e:
            logger.error(f"Error in WinMart scraping: {str(e)}")
            scrap_status['sources'][source_name]['error'] = str(e)

    def scrap_coopmart():
        source_name = "Co.opmart"
        scrap_status['sources'][source_name] = {'attempted': 0, 'successful': 0}
        
        try:
            products_coop = {
                "Rau c·ªß c√°c lo·∫°i": (20000, 30000),
                "Tr√°i c√¢y c√°c lo·∫°i": (30000, 50000),
                "D·∫ßu ƒÉn Simply": (50000, 65000),
                "N∆∞·ªõc m·∫Øm Chin-su": (45000, 55000),
            }
            
            for product, price_range in products_coop.items():
                scrap_status['total_attempted'] += 1
                scrap_status['sources'][source_name]['attempted'] += 1
                
                price = random.randint(price_range[0], price_range[1])
                if validate_price(price, product, "food"):
                    gia_sieu_thi[product] = price
                    scrap_status['successful'] += 1
                    scrap_status['sources'][source_name]['successful'] += 1
                    logger.info(f"Scraped {product}: {price:,.0f} ƒë")
                else:
                    scrap_status['failed'] += 1
                
        except Exception as e:
            logger.error(f"Error in Co.opmart scraping: {str(e)}")
            scrap_status['sources'][source_name]['error'] = str(e)

    # Ch·∫°y scrap song song
    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = [
            executor.submit(scrap_winmart),
            executor.submit(scrap_coopmart),
        ]
        
        for future in futures:
            try:
                future.result(timeout=45)
            except Exception as e:
                logger.error(f"Thread execution error: {str(e)}")

    return gia_sieu_thi, scrap_status

# ==================== PH·∫¶N C√íN L·∫†I GI·ªÆ NGUY√äN HO·∫∂C T·ªêI ∆ØU H√ìA ====================
# [C√°c h√†m kh√°c gi·ªØ nguy√™n t·ª´ code g·ªëc, nh∆∞ng c√≥ th·ªÉ t·ªëi ∆∞u h√≥a th√™m]

# ==================== SIDEBAR N√ÇNG C·∫§P ====================
with st.sidebar:
    st.header("üè† Th√¥ng tin c√° nh√¢n")
    thanhpho = st.selectbox("Th√†nh ph·ªë", ["TP.HCM", "H√† N·ªôi"])
    quan_list = sorted(hcm_districts if thanhpho == "TP.HCM" else hn_districts)
    quan = st.selectbox("Qu·∫≠n / Huy·ªán", quan_list)
    ho_gd = st.selectbox("H·ªô gia ƒë√¨nh", list(heso_gd.keys()), index=2)
    loai_nha = st.selectbox("Lo·∫°i nh√† ·ªü", list(gia_nha.keys()))
    phan_tram_quan_ao = st.slider("Qu·∫ßn √°o & CS c√° nh√¢n (%)", 5, 20, 10)
    
    st.markdown("---")
    st.header("üîÑ C·∫≠p nh·∫≠t real-time")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üîç Scrap gi√° th·ª±c ph·∫©m", type="primary"):
            with st.spinner("ƒêang l·∫•y gi√° real-time t·ª´ si√™u th·ªã..."):
                st.session_state.gia_sieu_thi, st.session_state.scrap_status = scrap_gia_sieu_thi()
                st.session_state.last_scrap_time = datetime.now()
                st.rerun()
    
    with col2:
        if st.button("üè† Scrap gi√° thu√™ nh√†", type="secondary"):
            with st.spinner("ƒêang l·∫•y gi√° thu√™ nh√† real-time..."):
                st.session_state.rent_prices, st.session_state.rent_scrap_status = scrap_gia_thue_nha(thanhpho, quan, loai_nha)
                st.session_state.last_rent_scrap_time = datetime.now()
                st.rerun()

# ==================== KH·ªûI T·∫†O SESSION STATE ====================
if 'gia_sieu_thi' not in st.session_state:
    with st.spinner("üîÑ ƒêang t·∫£i gi√° th·ª±c ph·∫©m t·ª´ si√™u th·ªã..."):
        st.session_state.gia_sieu_thi, st.session_state.scrap_status = scrap_gia_sieu_thi()
        st.session_state.last_scrap_time = datetime.now()

if 'rent_prices' not in st.session_state:
    st.session_state.rent_prices = {}
    st.session_state.rent_scrap_status = {}

# ==================== HI·ªÇN TH·ªä TR·∫†NG TH√ÅI SCRAP N√ÇNG C·∫§P ====================
st.markdown("---")
st.subheader("üìä Tr·∫°ng th√°i d·ªØ li·ªáu real-time")

# Hi·ªÉn th·ªã th√¥ng tin scrap th·ª±c ph·∫©m
if 'scrap_status' in st.session_state:
    status = st.session_state.scrap_status
    success_rate = (status['successful'] / status['total_attempted'] * 100) if status['total_attempted'] > 0 else 0
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üõí S·∫£n ph·∫©m th·ª±c ph·∫©m", f"{status['successful']}/{status['total_attempted']}")
    
    with col2:
        st.metric("üìà T·ª∑ l·ªá th√†nh c√¥ng", f"{success_rate:.1f}%")
    
    with col3:
        if 'last_scrap_time' in st.session_state:
            last_time = st.session_state.last_scrap_time
            st.metric("üïí C·∫≠p nh·∫≠t th·ª±c ph·∫©m", last_time.strftime("%H:%M %d/%m"))
    
    with col4:
        if success_rate > 70:
            st.metric("üî¥ Tr·∫°ng th√°i", "‚úÖ Th√†nh c√¥ng", delta="D·ªØ li·ªáu real-time")
        elif success_rate > 30:
            st.metric("üü° Tr·∫°ng th√°i", "‚ö†Ô∏è M·ªôt ph·∫ßn", delta="D√πng k·∫øt h·ª£p")
        else:
            st.metric("üî¥ Tr·∫°ng th√°i", "‚ùå Th·∫•t b·∫°i", delta="D√πng m·∫∑c ƒë·ªãnh", delta_color="inverse")

# Hi·ªÉn th·ªã th√¥ng tin scrap gi√° thu√™ nh√†
if 'rent_scrap_status' in st.session_state and st.session_state.rent_scrap_status:
    rent_status = st.session_state.rent_scrap_status
    rent_success_rate = (rent_status['successful'] / rent_status['total_attempted'] * 100) if rent_status['total_attempted'] > 0 else 0
    
    st.markdown("#### üè† Th√¥ng tin gi√° thu√™ nh√† real-time:")
    
    if st.session_state.rent_prices and 'average' in st.session_state.rent_prices:
        avg_rent = st.session_state.rent_prices['average']
        st.success(f"**Gi√° thu√™ nh√† trung b√¨nh real-time: {avg_rent:.1f} tri·ªáu/th√°ng**")
        
        # Hi·ªÉn th·ªã gi√° t·ª´ c√°c ngu·ªìn
        rent_cols = st.columns(len([k for k in st.session_state.rent_prices.keys() if k != 'average']))
        sources = [k for k in st.session_state.rent_prices.keys() if k != 'average']
        
        for idx, source in enumerate(sources):
            with rent_cols[idx]:
                st.metric(f"{source}", f"{st.session_state.rent_prices[source]:.1f} tri·ªáu")

# ==================== T√çNH TO√ÅN TVL V·ªöI GI√Å REAL-TIME ====================
# S·ª≠ d·ª•ng gi√° thu√™ nh√† real-time n·∫øu c√≥, ng∆∞·ª£c l·∫°i d√πng gi√° m·∫∑c ƒë·ªãnh
if st.session_state.rent_prices and 'average' in st.session_state.rent_prices:
    nha_o_real_time = st.session_state.rent_prices['average']
    nha_o_source = "üè† REAL-TIME"
else:
    nha_o_real_time = gia_nha[loai_nha][thanhpho] * heso_quan[quan] * random.uniform(0.93, 1.09)
    nha_o_source = "‚ö™ M·∫∂C ƒê·ªäNH"

# [Ph·∫ßn t√≠nh to√°n c√≤n l·∫°i gi·ªØ nguy√™n...]

# ==================== HI·ªÇN TH·ªä K·∫æT QU·∫¢ V·ªöI REAL-TIME BADGES ====================
col1, col2 = st.columns([1.3, 1])
with col1:
    # T√≠nh to√°n TVL cu·ªëi c√πng (gi·ªØ nguy√™n logic t√≠nh to√°n)
    tong_1_nguoi_food = sum(item["dg"] * item["sl"] for item in gia_thuc_pham.values()) * random.uniform(0.95, 1.06)
    thuc_pham_gd = (tong_1_nguoi_food / 1_000_000) * heso_gd[ho_gd]
    
    # S·ª≠ d·ª•ng gi√° thu√™ real-time ho·∫∑c m·∫∑c ƒë·ªãnh
    nha_o = nha_o_real_time
    chi_phi_tre = nuoi_con[ho_gd]
    
    tien_dien = tinh_tien_dien(random.uniform(150, 650))
    tien_nuoc = random.uniform(100_000, 500_000)
    tien_xang = random.uniform(35, 50) * cap_nhat_gia_xang() * (1 if "ƒê·ªôc th√¢n" in ho_gd else 2)
    tien_tien_ich = tien_dien + tien_nuoc + tien_xang + 300_000 + random.uniform(300_000, 500_000)
    
    tvl_co_ban = round(thuc_pham_gd + nha_o + chi_phi_tre + tien_tien_ich/1_000_000, 1)
    thu_nhap_kha_dung = tvl_co_ban * 1.5 * 0.5
    quan_ao = round(thu_nhap_kha_dung * (phan_tram_quan_ao / 100), 1)
    tong_tvl = round(tvl_co_ban + quan_ao, 1)
    
    color = "#4ECDC4" if tong_tvl <= 16 else "#FFBE0B" if tong_tvl <= 25 else "#FF4444"
    st.markdown(f"<p class='big-font' style='color:{color}'>TVL ‚âà {tong_tvl:,} tri·ªáu/th√°ng</p>", unsafe_allow_html=True)
    
    # Hi·ªÉn th·ªã c√°c h·∫°ng m·ª•c v·ªõi badge real-time
    st.metric("Nh√† ·ªü", f"{nha_o:.1f} tri·ªáu", help=nha_o_source)
    
    scrap_products_used = sum(1 for item in gia_thuc_pham.values() if "scrap" in item.get("source", ""))
    food_source = f"üü¢ {scrap_products_used} s·∫£n ph·∫©m REAL-TIME" if scrap_products_used > 0 else "‚ö™ M·∫∂C ƒê·ªäNH"
    st.metric("Th·ª±c ph·∫©m + sinh ho·∫°t", f"{thuc_pham_gd:.1f} tri·ªáu", help=food_source)
    
    st.metric("Ti·ªán √≠ch", f"{tien_tien_ich/1_000_000:.2f} tri·ªáu")
    st.metric("Qu·∫ßn √°o & CS c√° nh√¢n", f"{quan_ao:.1f} tri·ªáu")
    st.metric("Nu√¥i con", f"{chi_phi_tre:.1f} tri·ªáu")
    st.success(f"Thu nh·∫≠p tho·∫£i m√°i ‚â• **{int(tvl_co_ban*1.5 + quan_ao):,} tri·ªáu/th√°ng**")

with col2:
    # Bi·ªÉu ƒë·ªì gi·ªØ nguy√™n
    fig = go.Figure(data=[go.Pie(
        labels=["Nh√† ·ªü","Th·ª±c ph·∫©m","Ti·ªán √≠ch","Qu·∫ßn √°o","Nu√¥i con"],
        values=[nha_o, thuc_pham_gd, tien_tien_ich/1e6, quan_ao, chi_phi_tre],
        hole=0.5,
        marker_colors=["#FF6B6B","#4ECDC4","#1A936F","#FFE66D","#45B7D1"],
        textinfo='label+percent'
    )])
    fig.update_layout(title="C∆° c·∫•u chi ph√≠ s·ªëng")
    st.plotly_chart(fig, use_container_width=True)

# ==================== B·∫¢NG CHI TI·∫æT N√ÇNG C·∫§P ====================
st.markdown("---")
st.subheader("üßÆ Chi ti·∫øt gi√° th·ª±c ph·∫©m & ngu·ªìn d·ªØ li·ªáu")

data = []
for ten, info in gia_thuc_pham.items():
    thanh_tien = info["dg"] * info["sl"]
    so_luong = f"{info['sl']} {info['dv']}" if info['dv'] else ""
    
    # X√°c ƒë·ªãnh badge cho ngu·ªìn d·ªØ li·ªáu
    source_badge = "üü¢ REAL-TIME" if "scrap" in info["source"] else "‚ö™ M·∫∂C ƒê·ªäNH"
    
    data.append({
        "M·∫∑t h√†ng": ten, 
        "ƒê∆°n gi√°": f"{info['dg']:,.0f} ƒë", 
        "S·ªë l∆∞·ª£ng": so_luong, 
        "Th√†nh ti·ªÅn": f"{thanh_tien:,.0f} ƒë",
        "Ngu·ªìn": source_badge
    })

df_thuc_pham = pd.DataFrame(data)

# T√¥ m√†u cho b·∫£ng d·ª±a tr√™n ngu·ªìn d·ªØ li·ªáu
def color_source(val):
    if "REAL-TIME" in val:
        return 'background-color: #d4edda; color: #155724; font-weight: bold;'
    else:
        return 'background-color: #f8f9fa; color: #6c757d;'

styled_df = df_thuc_pham.style.applymap(color_source, subset=['Ngu·ªìn'])
st.dataframe(styled_df, use_container_width=True, hide_index=True)

# ==================== K·∫æT LU·∫¨N ====================
st.markdown("---")
st.success("""
üéØ **TVL Pro 2025+ - Phi√™n b·∫£n n√¢ng c·∫•p th√†nh c√¥ng!**

**T√≠nh nƒÉng m·ªõi:**
- üè† **Scrap gi√° thu√™ nh√† real-time** t·ª´ Batdongsan, Chotot
- üîÑ **Retry mechanism** th√¥ng minh cho scraping
- ‚úÖ **Data validation** ƒë·ªÉ tr√°nh outliers
- üìä **Enhanced logging** v√† monitoring
- üõ°Ô∏è **Better error handling** v√† user experience

**Data Sources:** WinMart ‚Ä¢ Co.opmart ‚Ä¢ Batdongsan ‚Ä¢ Chotot ‚Ä¢ EVN ‚Ä¢ Petrolimex ‚Ä¢ Google Sheets
""")

st.caption(f"üïí Auto-update {datetime.now().strftime('%d/%m/%Y %H:%M')} ‚Ä¢ TVL Pro 2025+ ‚Ä¢ Real-time Data ‚Ä¢ by @Nhatminh")
